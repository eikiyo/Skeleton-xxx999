
import React, { useState, useRef, useEffect, useCallback } from "react";
import { useLogs, type LogEntry } from "@/context/LogContext";
import { cn } from "@/lib/utils";
import { Mic, Send, Square, Loader2, RotateCcw } from "lucide-react"; // Added RotateCcw for refresh
import { Button } from '@/components/ui/button';


export default function InstructionChat() {
  const [input, setInput] = useState("");
  const { logs, addLog, clearLogs } = useLogs();
  const [isRecording, setIsRecording] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [isFetchingHistory, setIsFetchingHistory] = useState(true);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioStreamRef = useRef<MediaStream | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const mimeTypeRef = useRef<string>('');

  const mapSourceToDisplay = (source: string): string => {
    if (source === 'dev') return 'DEVELOPER';
    if (source === 'qa') return 'QA';
    return source.toUpperCase();
  }

  const scrollToBottom = useCallback(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, []);

  const fetchChatHistory = useCallback(async () => {
    setIsFetchingHistory(true);
    try {
      const res = await fetch("/api/chat/group");
      if (res.ok) {
        const data = await res.json();
        if (data.messages && Array.isArray(data.messages)) {
          // Clear only chat-related logs before adding history
          // This assumes other log sources are distinct and should be preserved
          // A more robust way would be to filter logs by a specific chat session ID if implemented
          // For now, we'll clear all logs from context and re-add, which might not be ideal if other logs are important to keep in sync.
          // A better approach for production: chat component manages its own message state, logs to LogContext for audit.
          // Given current LogContext, we re-populate.
          
          // Filter logs from context that are not from chat agents or user to preserve them
          const nonChatLogs = logs.filter(log => !['user', 'developer', 'qa', 'system', 'agent'].includes(log.source));
          clearLogs(); // Clears all logs
          nonChatLogs.forEach(log => addLog(log)); // Re-add non-chat logs

          data.messages.forEach((msg: { sender: string; text: string; ts: number }) => {
            addLog({
              source: msg.sender === 'dev' ? 'developer' : msg.sender === 'qa' ? 'qa' : msg.sender as LogEntry['source'],
              message: msg.text,
              timestamp: msg.ts,
              // id is auto-generated by addLog
            });
          });
        }
      } else {
        addLog({ source: 'system', message: `Error fetching chat history: ${res.statusText}` });
      }
    } catch (error) {
      addLog({ source: 'system', message: `Error fetching chat history: ${error instanceof Error ? error.message : String(error)}` });
    } finally {
      setIsFetchingHistory(false);
      scrollToBottom();
    }
  }, [addLog, clearLogs, logs, scrollToBottom]); // Added logs and clearLogs to dependencies

  useEffect(() => {
    fetchChatHistory();
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []); // Fetch history on mount

  useEffect(scrollToBottom, [logs, scrollToBottom]);

  function handleInputChange(e: React.ChangeEvent<HTMLTextAreaElement>) {
    setInput(e.target.value);
  }

  async function handleMicClick() {
    if (isRecording) {
      mediaRecorderRef.current?.stop();
      return;
    }
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      addLog({ source: 'system', message: "Microphone not supported by your browser."});
      return;
    }
    setInput('');
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioStreamRef.current = stream;
      const options = { mimeType: 'audio/webm;codecs=opus' };
      let recorder: MediaRecorder;
      if (MediaRecorder.isTypeSupported(options.mimeType)) {
        recorder = new MediaRecorder(stream, options);
        mimeTypeRef.current = options.mimeType;
      } else if (MediaRecorder.isTypeSupported('audio/webm')) {
        recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
        mimeTypeRef.current = 'audio/webm';
      } else {
        addLog({source: 'system', message: "No suitable audio recording format supported."});
        stream.getTracks().forEach(track => track.stop());
        audioStreamRef.current = null;
        return;
      }
      mediaRecorderRef.current = recorder;
      audioChunksRef.current = [];
      mediaRecorderRef.current.ondataavailable = (event) => event.data.size > 0 && audioChunksRef.current.push(event.data);
      mediaRecorderRef.current.onstop = async () => {
        setIsRecording(false);
        if (audioStreamRef.current) {
            audioStreamRef.current.getTracks().forEach(track => track.stop());
            audioStreamRef.current = null;
        }
        const audioBlob = new Blob(audioChunksRef.current, { type: mimeTypeRef.current });
        audioChunksRef.current = [];
        if (audioBlob.size === 0) {
            addLog({source: 'system', message: "Recording was empty."});
            setIsLoading(false);
            return;
        }
        setIsLoading(true);
        const reader = new FileReader();
        reader.readAsDataURL(audioBlob);
        reader.onloadend = async () => {
            const base64Audio = (reader.result as string).split(',')[1];
            try {
                const resp = await fetch("/api/whisper-transcribe", {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({ audioBase64: base64Audio, mimeType: mimeTypeRef.current }),
                });
                const data = await resp.json();
                if (resp.ok && data.transcript) {
                    setInput((prev) => (prev ? prev + " " : "") + data.transcript);
                    addLog({source: 'system', message: "Transcription successful."});
                } else {
                    addLog({source: 'system', message: `Transcription failed: ${data.error || 'Unknown error'}`});
                }
            } catch (error) {
                addLog({source: 'system', message: `Transcription request error: ${error instanceof Error ? error.message : String(error)}`});
            } finally { setIsLoading(false); }
        };
        reader.onerror = () => {
            addLog({source: 'system', message: "Error processing recorded audio."});
            setIsLoading(false);
        }
      };
      mediaRecorderRef.current.onerror = () => {
        addLog({source: 'system', message: "Error during recording."});
        setIsRecording(false);
        if (audioStreamRef.current) {
            audioStreamRef.current.getTracks().forEach(track => track.stop());
            audioStreamRef.current = null;
        }
      }
      mediaRecorderRef.current.start();
      setIsRecording(true);
      addLog({source: 'system', message: "Recording started..."});
    } catch (err) {
      addLog({source: 'system', message: `Microphone access error: ${err instanceof Error ? err.message : String(err)}. Please check browser permissions.`});
      setIsRecording(false);
    }
  }

  async function handleSend() {
    if (!input.trim()) return;
    setIsLoading(true);
    const userMessageContent = input;
    setInput("");

    // Add user's message to log immediately
    const userLogEntry: Omit<LogEntry, 'id'> = { // Omit id, it will be auto-generated
      source: "user" as LogEntry['source'],
      message: userMessageContent,
      timestamp: Date.now()
    };
    addLog(userLogEntry);


    try {
      const resp = await fetch("/api/chat/group", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ sender: 'user', text: userMessageContent }),
      });

      if (!resp.ok) {
        const errorData = await resp.json();
        addLog({ source: 'system', message: `Error sending message: ${errorData.error || resp.statusText}` });
      } else {
        const data = await resp.json();
        if (data.messages && Array.isArray(data.messages)) {
          // Process the full list of messages from the server
          // We need to be careful not to re-add messages already in the LogContext
          // A simple way is to find messages newer than the user's last message
          const lastUserMessageTimestamp = userLogEntry.timestamp;

          data.messages.forEach((msg: { sender: string; text: string; ts: number }) => {
            if (msg.ts > lastUserMessageTimestamp) { // Only add new messages
               let mappedSource: LogEntry['source'] = 'agent'; // Default
                if (msg.sender === 'dev') mappedSource = 'developer';
                else if (msg.sender === 'qa') mappedSource = 'qa';
                else if (msg.sender === 'user') mappedSource = 'user';
                // system messages are usually from frontend, backend could use 'system' sender too
                else if (msg.sender === 'system') mappedSource = 'system';


              addLog({
                source: mappedSource,
                message: msg.text,
                timestamp: msg.ts,
              });
            }
          });
        }
      }
    } catch (error) {
      addLog({ source: 'system', message: `Error sending message: ${error instanceof Error ? error.message : String(error)}` });
    } finally {
      setIsLoading(false);
      scrollToBottom();
    }
  }

  useEffect(() => {
    return () => {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
        mediaRecorderRef.current.stop();
      }
      if (audioStreamRef.current) {
         audioStreamRef.current.getTracks().forEach(track => track.stop());
         audioStreamRef.current = null;
      }
    };
  }, []);

  const getMessageBubbleClass = (source: LogEntry['source']) => {
    switch (source) {
      case 'user':
        return "bg-[#415A77] text-white rounded-xl rounded-br-none self-end";
      case 'developer': // Mapped from 'dev'
        return "bg-slate-700 text-slate-100 rounded-xl rounded-bl-none self-start";
      case 'qa': // Mapped from 'qa'
        return "bg-sky-700 text-sky-100 rounded-xl rounded-bl-none self-start";
      case 'system':
      case 'info':
      case 'error':
      case 'success':
      case 'agent':
      case 'git':
      case 'shell':
        return "bg-gray-600 text-gray-100 rounded-xl rounded-bl-none self-start";
      default:
        return "bg-slate-700 text-slate-100 rounded-xl rounded-bl-none self-start";
    }
  };

  const chatLogsToDisplay = logs.filter(log => ['user', 'developer', 'qa', 'system', 'agent'].includes(log.source));

  return (
    <div className="flex flex-col h-full bg-[#1B262C] text-white font-code rounded-lg shadow-xl">
      <div className="p-3 border-b border-[#2A3B47] flex justify-between items-center">
        <span className="text-lg font-semibold text-slate-300">Group Chat</span>
        <Button
            variant="ghost"
            size="icon"
            onClick={fetchChatHistory}
            disabled={isLoading || isRecording || isFetchingHistory}
            className="text-slate-400 hover:text-slate-200"
            aria-label="Refresh chat history"
          >
            {isFetchingHistory ? <Loader2 className="h-5 w-5 animate-spin" /> : <RotateCcw className="h-5 w-5" />}
          </Button>
      </div>

      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {isFetchingHistory && chatLogsToDisplay.length === 0 ? (
            <div className="flex justify-center items-center h-full">
                <Loader2 className="h-8 w-8 animate-spin text-slate-400" />
            </div>
        ) : chatLogsToDisplay.length === 0 && !isFetchingHistory ? (
          <div className="text-center text-slate-400 py-10">
            No messages yet. Start the conversation!
          </div>
        ) : (
          chatLogsToDisplay.map((log) => (
            <div key={log.id} className={`flex flex-col ${log.source === 'user' ? 'items-end' : 'items-start'}`}>
              <div
                className={cn("max-w-[75%] p-3 shadow-md text-sm", getMessageBubbleClass(log.source))}
              >
                <div className="flex items-center justify-between mb-1">
                  <span className="text-xs font-semibold opacity-90">
                    {mapSourceToDisplay(log.source)}
                  </span>
                  <span className="ml-3 text-xs font-normal opacity-70">
                    {new Date(log.timestamp).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })}
                  </span>
                </div>
                <div className="whitespace-pre-wrap break-words" dangerouslySetInnerHTML={{ __html: log.message.replace(/```([\s\S]*?)```/g, '<pre class="bg-slate-800 p-2 rounded-md my-1 text-xs overflow-x-auto"><code>$1</code></pre>') }}></div>
              </div>
            </div>
          ))
        )}
        <div ref={messagesEndRef} />
      </div>

      <div className="flex items-center border-t border-[#2A3B47] p-3 space-x-2 bg-slate-800/50">
        <button
          className={`p-2.5 rounded-full transition-colors ${isRecording ? "bg-red-500 hover:bg-red-600 animate-pulse" : "bg-[#415A77] hover:bg-[#55708d]"}`}
          onClick={handleMicClick}
          aria-label={isRecording ? "Stop Recording" : "Record Voice"}
          disabled={isLoading && !isRecording}
        >
          {isRecording ? <Square className="h-4 w-4 text-white" /> : <Mic className="h-4 w-4 text-white" />}
        </button>
        <textarea
          value={input}
          onChange={handleInputChange}
          onKeyDown={(e) => {
            if (e.key === 'Enter' && !e.shiftKey && !isLoading && !isRecording) {
              e.preventDefault();
              handleSend();
            }
          }}
          className="flex-1 bg-[#23313f] text-white rounded-lg p-2.5 resize-none border border-slate-600 focus:ring-2 focus:ring-[#778DA9] focus:border-transparent placeholder-slate-400 text-sm"
          rows={2}
          placeholder={isLoading ? "Agents are thinking..." : (isRecording ? "Recording..." : "Type your message or use the mic…")}
          disabled={isLoading || isRecording}
        />
        <Button
          onClick={handleSend}
          className="bg-[#778DA9] hover:bg-[#647a96] text-white px-5 py-2.5 rounded-lg transition-colors disabled:opacity-60 disabled:cursor-not-allowed flex items-center justify-center"
          disabled={isLoading || isRecording || !input.trim()}
          aria-label="Send instruction"
        >
          {isLoading && !isRecording ? <Loader2 className="h-5 w-5 animate-spin" /> : <Send className="h-5 w-5" />}
        </Button>
      </div>
    </div>
  );
}
